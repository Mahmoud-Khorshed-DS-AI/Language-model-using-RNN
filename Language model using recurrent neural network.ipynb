{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Let's import the required packages."]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T18:58:27.923726Z","iopub.status.busy":"2022-04-05T18:58:27.923415Z","iopub.status.idle":"2022-04-05T18:58:27.936722Z","shell.execute_reply":"2022-04-05T18:58:27.935783Z","shell.execute_reply.started":"2022-04-05T18:58:27.923685Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import re\n","import numpy as np\n","import os\n","import sys\n","import pickle\n","from time import time\n","start_time = time()\n","\n","# keras tokenizer\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow import keras\n","#required layers\n","from tensorflow.keras.layers import Embedding, LSTM, Dense,SimpleRNN, GRU, Dropout, Bidirectional\n","#to convert the output to one hot encoded data\n","from tensorflow.keras.utils import to_categorical\n","#nestrouv adam optimizer\n","from tensorflow.keras.optimizers import Nadam\n","#to convert tokens to ids\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.models import load_model\n","from tqdm.notebook import tqdm\n","\n","\n","print(sys.version)"]},{"cell_type":"markdown","metadata":{},"source":["### Read file data"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T18:58:29.869462Z","iopub.status.busy":"2022-04-05T18:58:29.869189Z","iopub.status.idle":"2022-04-05T18:58:29.971431Z","shell.execute_reply":"2022-04-05T18:58:29.970706Z","shell.execute_reply.started":"2022-04-05T18:58:29.869430Z"},"trusted":true},"outputs":[],"source":["#the source of the data used https://www.gutenberg.org/files/1497/1497-h/1497-h.htm#link2H_4_0004\n","file = open(\".your-path-here/republic_clean.txt\",mode=\"r\", encoding = \"utf8\")\n","#convert each line to item in a list\n","lines = file.read().splitlines()\n","#join them again into one string\n","lines = ' '.join(lines)\n","\n","lines = lines.replace('--', ' ')\n","# remove punctuations\n","lines = re.sub(r'[^\\w\\s]','',lines)\n","#remove more than followed speace\n","lines = re.sub(' +', ' ', lines)\n","lines = lines.split()\n","\n","#if the text has 'BOOK I' title keep the followed line, if doesn't has this title hash the followed code.\n","lines = lines[2:]\n","#remove non-alphabetic word in the text\n","lines = [word for word in lines if word.isalpha()]\n","#slice the text data\n","test_lines = lines[550:651]\n","print(f\"number of words in the text file after cleaning is : {len(lines)}\")\n","print(f\"number of words in the test file after cleaning is : {len(test_lines)}\")\n","\n","#convert them to one text again\n","lines = ' '.join(lines)\n","test_lines = ' '.join(test_lines)\n","#convert them to lower case\n","lines = lines.lower()\n","test_lines = test_lines.lower()"]},{"cell_type":"markdown","metadata":{},"source":["### Continue in preprocessing the text data"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T18:58:31.911648Z","iopub.status.busy":"2022-04-05T18:58:31.910854Z","iopub.status.idle":"2022-04-05T18:58:32.045255Z","shell.execute_reply":"2022-04-05T18:58:32.044481Z","shell.execute_reply.started":"2022-04-05T18:58:31.911607Z"},"trusted":true},"outputs":[],"source":["#instantiate the tokenizer\n","tokenizer = Tokenizer()\n","#fit on the data\n","tokenizer.fit_on_texts([lines])\n","#convert tokens to sequences\n","IDs = np.array(tokenizer.texts_to_sequences([lines])[0])\n","#change their type to int16 to consume less memory\n","IDs = IDs.astype('int16')\n","print(f\"number of IDs is: {len(IDs)}\")"]},{"cell_type":"markdown","metadata":{},"source":["### check the number of unique words"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T18:58:34.160695Z","iopub.status.busy":"2022-04-05T18:58:34.158981Z","iopub.status.idle":"2022-04-05T18:58:34.165966Z","shell.execute_reply":"2022-04-05T18:58:34.165113Z","shell.execute_reply.started":"2022-04-05T18:58:34.160643Z"},"trusted":true},"outputs":[],"source":["vocab_size = len(tokenizer.word_index) + 1\n","print(f\"number of unique words is: {vocab_size}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Organize the data into organized sequences each sequence has 51 value."]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T18:58:38.055977Z","iopub.status.busy":"2022-04-05T18:58:38.055438Z","iopub.status.idle":"2022-04-05T18:58:38.287012Z","shell.execute_reply":"2022-04-05T18:58:38.286205Z","shell.execute_reply.started":"2022-04-05T18:58:38.055939Z"},"trusted":true},"outputs":[],"source":["sequences = []\n","\n","for i in tqdm(range(50,len(IDs))):\n","    sequence = IDs[i-50:i+1]\n","    sequences.append(sequence)\n","print('the total number of sequences is:',len(sequences))\n","\n","sequences = np.array(sequences)\n","print(f\"The sequences shape is {sequences.shape}\")\n","print(f\"The number of words in each sequence is: {sequences.shape[1]}\")"]},{"cell_type":"markdown","metadata":{},"source":["## X will hold the 50 input words and y will hold the output words."]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T18:58:45.636240Z","iopub.status.busy":"2022-04-05T18:58:45.635717Z","iopub.status.idle":"2022-04-05T18:58:45.926002Z","shell.execute_reply":"2022-04-05T18:58:45.925182Z","shell.execute_reply.started":"2022-04-05T18:58:45.636202Z"},"trusted":true},"outputs":[],"source":["X = []\n","y = []\n","\n","for i in tqdm(sequences):\n","    X.append(i[0:-1])\n","    y.append(i[-1])\n","    \n","X = np.array(X)\n","y = np.array(y)\n","print(f\"The number of sequences in the input variable is: {X.shape[0]} and the number of input words in each sequence is {X.shape[1]}\")\n","print(f\"The number of sequences in the output variable is: {y.shape[0]} and each sequence has one output word\\n\")\n","\n","print(f\"First sequence is: {X[0]}, and it has {len(X[0])} words\")\n","print(f\"and the response is: {y[0]}\")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T18:58:47.622651Z","iopub.status.busy":"2022-04-05T18:58:47.621909Z","iopub.status.idle":"2022-04-05T18:58:47.863653Z","shell.execute_reply":"2022-04-05T18:58:47.862887Z","shell.execute_reply.started":"2022-04-05T18:58:47.622594Z"},"trusted":true},"outputs":[],"source":["#Convert the output to one hot encoded data.\n","y = to_categorical(y, num_classes=vocab_size)"]},{"cell_type":"markdown","metadata":{},"source":["### Function to plot the performance"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T18:58:50.764967Z","iopub.status.busy":"2022-04-05T18:58:50.764527Z","iopub.status.idle":"2022-04-05T18:58:50.773293Z","shell.execute_reply":"2022-04-05T18:58:50.772646Z","shell.execute_reply.started":"2022-04-05T18:58:50.764932Z"},"trusted":true},"outputs":[],"source":["def plot_performance(history):\n","    \"\"\"\n","    function to plot training price loss vs validation price loss and training price accuracy vs validation price accuracy.<br>\n","    \n","    params:\n","    \n","    history: model.fit object\n","    \n","    return:\n","    \n","    None\n","    \"\"\"\n","    val_loss_per_epoch = history.history['val_loss']\n","    loss_per_epoch = history.history['loss']\n","    val_accuracy_per_epoch = history.history['val_categorical_accuracy']\n","    accuracy_per_epoch = history.history['categorical_accuracy']\n","    plt.figure(figsize=(8,8))\n","    plt.title(f\"Training loss & validation loss with batch size 200\")\n","    plt.xlabel('epoch')\n","    plt.ylabel('loss function')\n","    plt.plot(np.arange(1,len(val_loss_per_epoch)+1),val_loss_per_epoch,label=f\"validation loss\")\n","    plt.plot(np.arange(1,len(loss_per_epoch)+1),loss_per_epoch,label = f\"training loss\")\n","    plt.legend(loc=\"upper left\")\n","    plt.show()\n","    plt.figure(figsize=(8,8))\n","    plt.title(f\"Training accuracy & validation accuracy with batch size 200\")\n","    plt.xlabel('epoch')\n","    plt.ylabel('accuracy')\n","    plt.plot(np.arange(1,len(val_accuracy_per_epoch)+1),val_accuracy_per_epoch,label=\"validation accuracy\")\n","    plt.plot(np.arange(1,len(accuracy_per_epoch)+1),accuracy_per_epoch,label = \"training accuracy\")\n","    #plt.xticks(np.arange(0, 55, 5))\n","    #plt.yticks(np.arange(0, 105, 5))\n","    plt.legend(loc=\"upper left\")\n","    plt.show()"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T18:58:51.796259Z","iopub.status.busy":"2022-04-05T18:58:51.795784Z","iopub.status.idle":"2022-04-05T18:58:51.807073Z","shell.execute_reply":"2022-04-05T18:58:51.806341Z","shell.execute_reply.started":"2022-04-05T18:58:51.796225Z"},"trusted":true},"outputs":[],"source":["def predict_next_word_proba(recurrent_model, tokenizer, data):\n","  #convert text to array\n","  data = data.split()\n","  #last word will be the true value\n","  correct_word = data[-1]\n","  #take last 50 words to be the test data\n","  data = data[50:-1]\n","\n","  #convert to data to string\n","  data = ' '.join(data)\n","  #convert them to id sequences using our predefined tokenizer\n","  sequence = tokenizer.texts_to_sequences([data])\n","  #convert test sequence to numpy array\n","  sequence = np.array(sequence)\n","  #start predict the probability of the next word\n","  proba = recurrent_model.predict(sequence)['next_word']\n","  #sort the probabilities\n","  sorted_proba = np.sort(recurrent_model.predict(sequence)['next_word'][0],kind = 'mergesort')\n","  L = np.argsort(-proba)\n","  #get the index of largest probability\n","  largest_value_index = L[:,0]\n","  #get the index of the second largest probability\n","  second_largest_value_index = L[:,1]\n","  #get the index of third largest probability\n","  third_largest_value_index = L[:,2]\n","  #get the largest probability\n","  largest_proba = sorted_proba[-1]\n","  #get the second largest probability\n","  second_largest_proba = sorted_proba[-2]\n","  #get the third largest probability\n","  third_largest_proba = sorted_proba[-3]\n","\n","  #define three variables each variable will hold the value of the next word first variable will be the most predicted value\n","  next_word_1 = None\n","  next_word_2 = None\n","  next_word_3 = None\n","\n","  #this for loop will get the word as string\n","  #value here is the id of the word and the key is the word itself\n","  for key, value in tokenizer.word_index.items():\n","      if value == largest_value_index[0]:\n","          next_word_1 = key\n","          continue\n","      elif value == second_largest_value_index[0]:\n","          next_word_2 = key\n","          continue\n","      elif value == third_largest_value_index[0]:\n","          next_word_3 = key\n","          continue\n","\n","  return f\"Correct word is [{correct_word}]\\n\\nthe predict next word will be one of these three words (the higher probability the higher chance to be the next word)\\n\\nthe predicted next word is [{next_word_1}] with the largest probability {round(largest_proba,3)}\\nthe next word could be [{next_word_2}] with the second largest probability {round(second_largest_proba,3)}\\nand it could be [{next_word_3}] with the third largest probability {round(third_largest_proba,3)}\""]},{"cell_type":"markdown","metadata":{},"source":["### First trial: Simple recurrent language model"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:49:19.714700Z","iopub.status.busy":"2022-04-05T19:49:19.713075Z","iopub.status.idle":"2022-04-05T19:49:20.429172Z","shell.execute_reply":"2022-04-05T19:49:20.428373Z","shell.execute_reply.started":"2022-04-05T19:49:19.714652Z"},"trusted":true},"outputs":[],"source":["first_start_time = time()\n","\n","keras.backend.clear_session()\n","in_text = keras.Input(batch_shape=(None, 50))\n","\n","#embedding layer uses a distributed representation for words so that different words with similar meanings will have a similar representation.\n","embedded = keras.layers.Embedding(vocab_size, 50)(in_text)\n","#simple rnn\n","#relu activation function to avoid vanishing gradient as much as we can\n","RNN =  SimpleRNN(units = 1000)(embedded)\n","\n","#averaged = tf.reduce_mean(bi_lstm, axis=1)\n","drop_out = Dropout(rate=0.2)(RNN)\n","\n","fused = Dense(128, activation='relu')(drop_out)\n","output = Dense(vocab_size, activation='softmax')(fused)\n","\n","rnn_model = keras.Model(\n","    inputs={\n","        'previous_words': in_text,\n","    },\n","    outputs={\n","        'next_word': output,\n","    },\n",")\n","rnn_model.summary()\n","tf.keras.utils.plot_model(rnn_model,to_file='first model.png', show_shapes=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rnn_model.compile(\n","loss={\n","    'next_word':\"categorical_crossentropy\"\n","},\n","metrics={\n","    'next_word':[\"categorical_accuracy\"]\n","},\n","loss_weights={\n","    'next_word':1,\n","},\n","optimizer=Nadam(learning_rate=0.001)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["checkpoint = ModelCheckpoint(\"simple_rnn_model.h5\", monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=False)\n","early_stopping = EarlyStopping(monitor='val_categorical_accuracy', patience=5)\n","#To train the first model on GPU\n","tf.debugging.set_log_device_placement(True)\n","#Start training the first model\n","rnn_history = rnn_model.fit(x={'previous_words': X}, y= {'next_word':y},validation_split=0.2, epochs=50, batch_size=256, callbacks=[checkpoint,early_stopping])"]},{"cell_type":"markdown","metadata":{},"source":["### plotting first model performance"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_performance(rnn_history)"]},{"cell_type":"markdown","metadata":{},"source":["### Start predicting the next word probability using the first model."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#load the best model which gave us the best validation accuracy to predict the test data.\n","rnn_model = load_model('simple_rnn_model.h5')\n","print('input data: '+test_lines[:-3]+' .....')\n","print('\\n')\n","print(predict_next_word_proba(rnn_model, tokenizer, test_lines))"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate the total time taken to train and test the first model."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["first_end_time = time()\n","total_time = first_end_time - first_start_time\n","result = '{0:02.0f} minutes and {1:02.0f} seconds'.format(*divmod((total_time/60) * 60, 60))\n","print(f\"The total time taken to train and test the first model was: {result}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Second Trail: LSTM then gru layer to memorize sequences."]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:49:17.554143Z","iopub.status.busy":"2022-04-05T19:49:17.553893Z","iopub.status.idle":"2022-04-05T19:49:19.707899Z","shell.execute_reply":"2022-04-05T19:49:19.706355Z","shell.execute_reply.started":"2022-04-05T19:49:17.554108Z"},"trusted":true},"outputs":[],"source":["second_start_time = time()\n","\n","keras.backend.clear_session()\n","in_text = keras.Input(batch_shape=(None, 50))\n","\n","#embedding layer uses a distributed representation for words so that different words with similar meanings will have a similar representation.\n","embedded = keras.layers.Embedding(vocab_size, 50)(in_text)\n","#lstm layer\n","lstm =  LSTM(units = 1000,return_sequences=True)(embedded)\n","gru =  GRU(units = 736)(lstm)\n","\n","drop_out = Dropout(rate=0.2)(gru)\n","\n","fused = Dense(128, activation='relu')(drop_out)\n","output = Dense(vocab_size, activation='softmax')(fused)\n","\n","second_model = keras.Model(\n","    inputs={\n","        'previous_words': in_text,\n","    },\n","    outputs={\n","        'next_word': output,\n","    },\n",")\n","second_model.summary()\n","tf.keras.utils.plot_model(second_model,to_file='second model.png', show_shapes=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["second_model.compile(\n","loss={\n","    'next_word':\"categorical_crossentropy\"\n","},\n","metrics={\n","    'next_word':[\"categorical_accuracy\"]\n","},\n","loss_weights={\n","    'next_word':1,\n","},\n","optimizer=Nadam(learning_rate=0.001)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["checkpoint = ModelCheckpoint(\"second_model.h5\", monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=False)\n","early_stopping = EarlyStopping(monitor='val_categorical_accuracy', patience=5)\n","#To train the second model on GPU\n","tf.debugging.set_log_device_placement(True)\n","#Start training the second model.\n","second_history = second_model.fit(x={'previous_words': X}, y= {'next_word':y},validation_split=0.2, epochs=50, batch_size=256, callbacks=[checkpoint,early_stopping])"]},{"cell_type":"markdown","metadata":{},"source":["### Plotting second model preformance"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_performance(second_history)"]},{"cell_type":"markdown","metadata":{},"source":["### Start predicting the next word probability using the second model."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#load the best model which gave us the best validation accuracy to predict the test data.\n","second_model = load_model('second_model.h5')\n","print('input data: '+test_lines[:-3]+' .....')\n","print('\\n')\n","print(predict_next_word_proba(second_model, tokenizer, test_lines))"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate the total time taken to train and test the second model."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["second_end_time = time()\n","total_time = second_end_time - second_start_time\n","result = '{0:02.0f} minutes and {1:02.0f} seconds'.format(*divmod((total_time/60) * 60, 60))\n","print(f\"The total time taken to train and test the second model was: {result}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Third trial: GRU Model"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:30:43.281708Z","iopub.status.busy":"2022-04-05T19:30:43.281477Z","iopub.status.idle":"2022-04-05T19:30:45.239198Z","shell.execute_reply":"2022-04-05T19:30:45.238388Z","shell.execute_reply.started":"2022-04-05T19:30:43.281682Z"},"trusted":true},"outputs":[],"source":["third_start_time = time()\n","\n","keras.backend.clear_session()\n","in_text = keras.Input(batch_shape=(None, 50))\n","\n","#embedding layer uses a distributed representation for words so that different words with similar meanings will have a similar representation.\n","embedded = keras.layers.Embedding(vocab_size, 50)(in_text)\n","#GRU layer\n","gru =  GRU(units = 1000,return_sequences=True)(embedded)\n","lstm =  LSTM(units = 736)(gru)\n","\n","drop_out = Dropout(rate=0.2)(lstm)\n","\n","fused = Dense(128, activation='relu')(drop_out)\n","output = Dense(vocab_size, activation='softmax')(fused)\n","\n","third_model = keras.Model(\n","    inputs={\n","        'previous_words': in_text,\n","    },\n","    outputs={\n","        'next_word': output,\n","    },\n",")\n","third_model.summary()\n","tf.keras.utils.plot_model(third_model,to_file='third model.png', show_shapes=True)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:30:45.241446Z","iopub.status.busy":"2022-04-05T19:30:45.240891Z","iopub.status.idle":"2022-04-05T19:30:45.254663Z","shell.execute_reply":"2022-04-05T19:30:45.253784Z","shell.execute_reply.started":"2022-04-05T19:30:45.241405Z"},"trusted":true},"outputs":[],"source":["third_model.compile(\n","loss={\n","    'next_word':\"categorical_crossentropy\"\n","},\n","metrics={\n","    'next_word':[\"categorical_accuracy\"]\n","},\n","loss_weights={\n","    'next_word':1,\n","},\n","optimizer=Nadam(learning_rate=0.001)\n",")"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:30:45.256731Z","iopub.status.busy":"2022-04-05T19:30:45.256428Z","iopub.status.idle":"2022-04-05T19:48:41.969223Z","shell.execute_reply":"2022-04-05T19:48:41.968399Z","shell.execute_reply.started":"2022-04-05T19:30:45.256694Z"},"trusted":true},"outputs":[],"source":["checkpoint = ModelCheckpoint(\"third_model.h5\", monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=False)\n","early_stopping = EarlyStopping(monitor='val_categorical_accuracy', patience=5)\n","#To train the third model on GPU\n","tf.debugging.set_log_device_placement(True)\n","#Start training the third model\n","third_history = third_model.fit(x={'previous_words': X}, y= {'next_word':y},validation_split=0.2, epochs=50, batch_size=256, callbacks=[checkpoint,early_stopping])"]},{"cell_type":"markdown","metadata":{},"source":["### Plotting third model performance"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:48:41.977627Z","iopub.status.busy":"2022-04-05T19:48:41.972393Z","iopub.status.idle":"2022-04-05T19:49:15.735070Z","shell.execute_reply":"2022-04-05T19:49:15.734382Z","shell.execute_reply.started":"2022-04-05T19:48:41.977588Z"},"trusted":true},"outputs":[],"source":["plot_performance(third_history)"]},{"cell_type":"markdown","metadata":{},"source":["### Start predicting the next word probability using the third model."]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:49:15.736521Z","iopub.status.busy":"2022-04-05T19:49:15.736243Z","iopub.status.idle":"2022-04-05T19:49:17.528298Z","shell.execute_reply":"2022-04-05T19:49:17.527572Z","shell.execute_reply.started":"2022-04-05T19:49:15.736470Z"},"trusted":true},"outputs":[],"source":["#load the best model which gave us the best validation accuracy to predict the test data.\n","third_model = load_model('third_model.h5')\n","print('input data: '+test_lines[:-3]+' .....')\n","print('\\n')\n","print(predict_next_word_proba(third_model, tokenizer, test_lines))"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate the total time taken to train and test the third model."]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:49:17.540219Z","iopub.status.busy":"2022-04-05T19:49:17.539876Z","iopub.status.idle":"2022-04-05T19:49:17.552670Z","shell.execute_reply":"2022-04-05T19:49:17.551736Z","shell.execute_reply.started":"2022-04-05T19:49:17.540185Z"},"trusted":true},"outputs":[],"source":["third_end_time = time()\n","total_time = third_end_time - third_start_time\n","result = '{0:02.0f} minutes and {1:02.0f} seconds'.format(*divmod((total_time/60) * 60, 60))\n","print(f\"The total time taken to train and test the third model was: {result}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Fourth trial: Bi-directional LSTM"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:15:07.313142Z","iopub.status.busy":"2022-04-05T19:15:07.312797Z","iopub.status.idle":"2022-04-05T19:15:10.657211Z","shell.execute_reply":"2022-04-05T19:15:10.656435Z","shell.execute_reply.started":"2022-04-05T19:15:07.313107Z"},"trusted":true},"outputs":[],"source":["fourth_start_time = time()\n","\n","keras.backend.clear_session()\n","in_text = keras.Input(batch_shape=(None, 50))\n","\n","#embedding layer uses a distributed representation for words so that different words with similar meanings will have a similar representation.\n","embedded = keras.layers.Embedding(vocab_size, 50)(in_text)\n","#Bi-directional LSTM layer\n","bi_lstm =  Bidirectional(LSTM(units = 1000))(embedded)\n","\n","drop_out = Dropout(rate=0.2)(bi_lstm)\n","\n","fused = Dense(128, activation='relu')(drop_out)\n","output = Dense(vocab_size, activation='softmax')(fused)\n","\n","fourth_model = keras.Model(\n","    inputs={\n","        'previous_words': in_text,\n","    },\n","    outputs={\n","        'next_word': output,\n","    },\n",")\n","fourth_model.summary()\n","tf.keras.utils.plot_model(fourth_model,to_file='fourth model.png', show_shapes=True)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:15:10.659422Z","iopub.status.busy":"2022-04-05T19:15:10.658875Z","iopub.status.idle":"2022-04-05T19:15:10.672236Z","shell.execute_reply":"2022-04-05T19:15:10.671520Z","shell.execute_reply.started":"2022-04-05T19:15:10.659379Z"},"trusted":true},"outputs":[],"source":["fourth_model.compile(\n","loss={\n","    'next_word':\"categorical_crossentropy\"\n","},\n","metrics={\n","    'next_word':[\"categorical_accuracy\"]\n","},\n","loss_weights={\n","    'next_word':1,\n","},\n","optimizer=Nadam(learning_rate=0.001)\n",")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:15:10.673723Z","iopub.status.busy":"2022-04-05T19:15:10.673378Z","iopub.status.idle":"2022-04-05T19:30:20.752917Z","shell.execute_reply":"2022-04-05T19:30:20.752195Z","shell.execute_reply.started":"2022-04-05T19:15:10.673686Z"},"trusted":true},"outputs":[],"source":["checkpoint = ModelCheckpoint(\"fourth_model.h5\", monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=False)\n","early_stopping = EarlyStopping(monitor='val_categorical_accuracy', patience=5)\n","#To train the fourth model on GPU\n","tf.debugging.set_log_device_placement(True)\n","#Start training the fourth model\n","fourth_history = fourth_model.fit(x={'previous_words': X}, y= {'next_word':y},validation_split=0.2, epochs=50, batch_size=256, callbacks=[checkpoint,early_stopping])"]},{"cell_type":"markdown","metadata":{},"source":["### Plotting the fourth model preformance"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:30:20.754526Z","iopub.status.busy":"2022-04-05T19:30:20.754285Z","iopub.status.idle":"2022-04-05T19:30:40.362005Z","shell.execute_reply":"2022-04-05T19:30:40.361329Z","shell.execute_reply.started":"2022-04-05T19:30:20.754481Z"},"trusted":true},"outputs":[],"source":["plot_performance(fourth_history)"]},{"cell_type":"markdown","metadata":{},"source":["### Start predicting the next word probability using the fourth model."]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:30:40.363905Z","iopub.status.busy":"2022-04-05T19:30:40.363432Z","iopub.status.idle":"2022-04-05T19:30:43.278968Z","shell.execute_reply":"2022-04-05T19:30:43.278198Z","shell.execute_reply.started":"2022-04-05T19:30:40.363867Z"},"trusted":true},"outputs":[],"source":["#load the best model which gave us the best validation accuracy to predict the test data.\n","fourth_model = load_model('fourth_model.h5')\n","print('input data: '+test_lines[:-3]+' .....')\n","print('\\n')\n","print(predict_next_word_proba(fourth_model, tokenizer, test_lines))"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate the total time taken to train and test the fourth model."]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:49:17.532079Z","iopub.status.busy":"2022-04-05T19:49:17.531457Z","iopub.status.idle":"2022-04-05T19:49:17.538436Z","shell.execute_reply":"2022-04-05T19:49:17.537298Z","shell.execute_reply.started":"2022-04-05T19:49:17.532036Z"},"trusted":true},"outputs":[],"source":["fourth_end_time = time()\n","total_time = fourth_end_time - fourth_start_time\n","result = '{0:02.0f} minutes and {1:02.0f} seconds'.format(*divmod((total_time/60) * 60, 60))\n","print(f\"The total time taken to train and test the fourth model was: {result}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Fifth trial: Bi-directional GRU to memorize the sequences."]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T18:59:05.415177Z","iopub.status.busy":"2022-04-05T18:59:05.414406Z","iopub.status.idle":"2022-04-05T18:59:07.364116Z","shell.execute_reply":"2022-04-05T18:59:07.363345Z","shell.execute_reply.started":"2022-04-05T18:59:05.415132Z"},"trusted":true},"outputs":[],"source":["fifth_start_time = time()\n","\n","keras.backend.clear_session()\n","in_text = keras.Input(batch_shape=(None, 50))\n","\n","#embedding layer uses a distributed representation for words so that different words with similar meanings will have a similar representation.\n","embedded = keras.layers.Embedding(vocab_size, 50)(in_text)\n","#Bi-directional GRU layer\n","bi_gru =  Bidirectional(GRU(units = 1000))(embedded)\n","\n","drop_out = Dropout(rate=0.2)(bi_gru)\n","\n","fused = Dense(128, activation='relu')(drop_out)\n","output = Dense(vocab_size, activation='softmax')(fused)\n","\n","fifth_model = keras.Model(\n","    inputs={\n","        'previous_words': in_text,\n","    },\n","    outputs={\n","        'next_word': output,\n","    },\n",")\n","fifth_model.summary()\n","tf.keras.utils.plot_model(fifth_model,to_file='fifth model.png', show_shapes=True)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:00:28.546169Z","iopub.status.busy":"2022-04-05T19:00:28.545898Z","iopub.status.idle":"2022-04-05T19:00:28.559256Z","shell.execute_reply":"2022-04-05T19:00:28.558466Z","shell.execute_reply.started":"2022-04-05T19:00:28.546138Z"},"trusted":true},"outputs":[],"source":["fifth_model.compile(\n","loss={\n","    'next_word':\"categorical_crossentropy\"\n","},\n","metrics={\n","    'next_word':[\"categorical_accuracy\"]\n","},\n","loss_weights={\n","    'next_word':1,\n","},\n","optimizer=Nadam(learning_rate=0.001)\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Starting training the fifth model."]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:00:31.409135Z","iopub.status.busy":"2022-04-05T19:00:31.408877Z","iopub.status.idle":"2022-04-05T19:14:03.431093Z","shell.execute_reply":"2022-04-05T19:14:03.430207Z","shell.execute_reply.started":"2022-04-05T19:00:31.409107Z"},"trusted":true},"outputs":[],"source":["checkpoint = ModelCheckpoint(\"fifth_model.h5\", monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=False)\n","early_stopping = EarlyStopping(monitor='val_categorical_accuracy', patience=7)\n","#To train the fifth model on GPU\n","tf.debugging.set_log_device_placement(True)\n","#Start training the fifth model\n","fifth_history = fifth_model.fit(x={'previous_words': X}, y= {'next_word':y},validation_split=0.2, epochs=50, batch_size=256, callbacks=[checkpoint,early_stopping])"]},{"cell_type":"markdown","metadata":{},"source":["### Plotting the fifth model performance."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T17:35:33.930756Z","iopub.status.busy":"2022-04-05T17:35:33.930552Z","iopub.status.idle":"2022-04-05T17:35:55.645162Z","shell.execute_reply":"2022-04-05T17:35:55.644483Z","shell.execute_reply.started":"2022-04-05T17:35:33.930731Z"},"trusted":true},"outputs":[],"source":["plot_performance(fifth_history)"]},{"cell_type":"markdown","metadata":{},"source":["### Start predicting the next word probability using the fifth model."]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:15:04.452669Z","iopub.status.busy":"2022-04-05T19:15:04.451805Z","iopub.status.idle":"2022-04-05T19:15:07.301398Z","shell.execute_reply":"2022-04-05T19:15:07.300696Z","shell.execute_reply.started":"2022-04-05T19:15:04.452630Z"},"trusted":true},"outputs":[],"source":["#load the best model which gave us the best validation accuracy to predict the test data.\n","fifth_model = load_model('fifth_model.h5')\n","print('input data: '+test_lines[:-3]+' .....')\n","print('\\n')\n","print(predict_next_word_proba(fifth_model, tokenizer, test_lines))"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate the total time taken to train and test the fifth model."]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:15:07.303688Z","iopub.status.busy":"2022-04-05T19:15:07.303432Z","iopub.status.idle":"2022-04-05T19:15:07.311301Z","shell.execute_reply":"2022-04-05T19:15:07.310546Z","shell.execute_reply.started":"2022-04-05T19:15:07.303654Z"},"trusted":true},"outputs":[],"source":["fifth_end_time = time()\n","total_time = fifth_end_time - fifth_start_time\n","result = '{0:02.0f} minutes and {1:02.0f} seconds'.format(*divmod((total_time/60) * 60, 60))\n","print(f\"The total time taken to train and test the fifth model was: {result}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Last trial: Bi-directional GRU connected with Bi-directional LSTM to memorize the sequences. "]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-04-05T19:14:03.432936Z","iopub.status.busy":"2022-04-05T19:14:03.432697Z","iopub.status.idle":"2022-04-05T19:15:04.450247Z","shell.execute_reply":"2022-04-05T19:15:04.449416Z","shell.execute_reply.started":"2022-04-05T19:14:03.432905Z"},"trusted":true},"outputs":[],"source":["last_start_time = time()\n","\n","keras.backend.clear_session()\n","in_text = keras.Input(batch_shape=(None, 50))\n","\n","#embedding layer uses a distributed representation for words so that different words with similar meanings will have a similar representation.\n","embedded = keras.layers.Embedding(vocab_size, 50)(in_text)\n","#Bi-directional GRU layer\n","bi_gru =  Bidirectional(GRU(units = 1000, return_sequences = True))(embedded)\n","bi_lstm = Bidirectional(LSTM(units = 736))(bi_gru)\n","\n","drop_out = Dropout(rate=0.2)(bi_lstm)\n","\n","fused = Dense(128, activation='relu')(drop_out)\n","output = Dense(vocab_size, activation='softmax')(fused)\n","\n","last_model = keras.Model(\n","    inputs={\n","        'previous_words': in_text,\n","    },\n","    outputs={\n","        'next_word': output,\n","    },\n",")\n","last_model.summary()\n","tf.keras.utils.plot_model(last_model,to_file='last model.png', show_shapes=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["last_model.compile(\n","loss={\n","    'next_word':\"categorical_crossentropy\"\n","},\n","metrics={\n","    'next_word':[\"categorical_accuracy\"]\n","},\n","loss_weights={\n","    'next_word':1,\n","},\n","optimizer=Nadam(learning_rate=0.001)\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Start training the last model."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["checkpoint = ModelCheckpoint(\"last_model.h5\", monitor='val_categorical_accuracy', verbose=1, save_best_only=True, save_weights_only=False)\n","early_stopping = EarlyStopping(monitor='val_categorical_accuracy', patience=7)\n","#To train the last model on GPU\n","tf.debugging.set_log_device_placement(True)\n","#Start training the last models\n","last_history = last_model.fit(x={'previous_words': X}, y= {'next_word':y},validation_split=0.2, epochs=50, batch_size=256, callbacks=[checkpoint,early_stopping])"]},{"cell_type":"markdown","metadata":{},"source":["### Plotting the last model performance."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_performance(last_history)"]},{"cell_type":"markdown","metadata":{},"source":["### Start predicting the next word probability using the last model."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#load the best model which gave us the best validation accuracy to predict the test data.\n","last_model = load_model('last_model.h5')\n","print('input data: '+test_lines[:-3]+' .....')\n","print('\\n')\n","print(predict_next_word_proba(last_model, tokenizer, test_lines))"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate the total time taken to train and test the last model."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["last_end_time = time()\n","total_time = last_end_time - last_start_time\n","result = '{0:02.0f} minutes and {1:02.0f} seconds'.format(*divmod((total_time/60) * 60, 60))\n","print(f\"The total time taken to train and test the last model was: {result}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate the total time taken to run the whole code."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["end_time = time()\n","total_time = end_time - start_time\n","result = '{0:02.0f} minutes and {1:02.0f} seconds'.format(*divmod((total_time/60) * 60, 60))\n","print(f\"The total time taken to run this code was: {result}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
